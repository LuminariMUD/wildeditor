# Wildeditor MCP Server - Development Environment
# Copy this file to .env.development and configure your values

# Server Settings
WILDEDITOR_NODE_ENV=development
WILDEDITOR_MCP_PORT=8001
WILDEDITOR_HOST=0.0.0.0
WILDEDITOR_LOG_LEVEL=DEBUG

# Authentication - Two-key system
# Backend API key (shared with backend for API calls)
WILDEDITOR_API_KEY=your-backend-api-key-here
# MCP operations key (for AI agents)
WILDEDITOR_MCP_KEY=your-mcp-operations-key-here

# Backend Integration
WILDEDITOR_BACKEND_URL=http://localhost:8000
WILDEDITOR_BACKEND_API_BASE=/api

# CORS Configuration
WILDEDITOR_CORS_ORIGINS=http://localhost:3000,http://localhost:5173

# AI Provider Configuration
# Priority order: 1. AI_PROVIDER env var, 2. Available API keys (OpenAI > Anthropic > DeepSeek > Ollama)
AI_PROVIDER=none  # Options: openai, anthropic, deepseek, ollama, none (auto-detect from keys)

# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-4-turbo-preview  # Options: gpt-4-turbo-preview, gpt-4, gpt-3.5-turbo

# Anthropic Configuration
ANTHROPIC_API_KEY=your-anthropic-api-key-here
ANTHROPIC_MODEL=claude-3-opus-20240229  # Options: claude-3-opus-20240229, claude-3-sonnet-20240229

# DeepSeek Configuration
DEEPSEEK_API_KEY=your-deepseek-api-key-here
DEEPSEEK_MODEL=deepseek-chat  # Options: deepseek-chat, deepseek-coder

# Ollama Configuration (for local LLMs)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2  # Options: llama2, mistral, codellama, etc.
